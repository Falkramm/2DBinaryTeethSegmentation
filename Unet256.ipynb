{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwAhyeGuDS6s",
        "outputId": "504b698d-81e8-430c-f3a1-e155285261fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2023-12-09T17:11:43.138078349Z",
          "start_time": "2023-12-09T17:11:39.637331338Z"
        },
        "id": "yVBn4fq7-B68"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import skimage.io  #Used for imshow function\n",
        "import skimage.transform  #Used for resize function\n",
        "from skimage.morphology import label  #Used for Run-Length-Encoding RLE to create final submission\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:11:43.151142392Z",
          "start_time": "2023-12-09T17:11:43.140617603Z"
        },
        "id": "4L79hnEs-B6-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "data_dir = 'data_256/'\n",
        "images_dir = 'images/'\n",
        "masks_dir = 'masks/'\n",
        "WIDTH = 256\n",
        "HEIGHT = 256\n",
        "CLASSES = 1"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:45.369811060Z",
          "start_time": "2023-12-09T17:31:45.328125675Z"
        },
        "id": "nXRK_kfw-B6-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = Image.open(data_dir + images_dir + image_path)  #.convert('L')  # Преобразуем в оттенки серого\n",
        "    return np.array(image)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_mask(mask_path):\n",
        "    mask = Image.open(data_dir + masks_dir + mask_path).convert('L')  # Преобразуем в оттенки серого\n",
        "    mask_array = np.array(mask)\n",
        "    mask_float = mask_array.astype(float) / 255.0  # Преобразуем в тип float и нормализуем значения до диапазона [0, 1]\n",
        "    return mask_float\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:46.144671869Z",
          "start_time": "2023-12-09T17:31:46.134829810Z"
        },
        "id": "Ffr9l0Bq-B6_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": [
        "# # Подготовка данных\n",
        "image_paths = sorted(os.listdir(data_dir + images_dir))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:47.063987100Z",
          "start_time": "2023-12-09T17:31:47.056756986Z"
        },
        "id": "g_aP5-2o-B6_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1.png', '10.png', '100.png', '101.png', '102.png', '103.png', '104.png', '105.png', '106.png', '107.png', '108.png', '109.png', '11.png', '110.png', '111.png', '112.png', '113.png', '114.png', '115.png', '116.png', '117.png', '118.png', '119.png', '12.png', '120.png', '121.png', '122.png', '123.png', '124.png', '125.png', '126.png', '127.png', '128.png', '129.png', '13.png', '130.png', '131.png', '132.png', '133.png', '134.png', '135.png', '136.png', '137.png', '138.png', '139.png', '14.png', '140.png', '141.png', '142.png', '143.png', '144.png', '145.png', '146.png', '147.png', '148.png', '149.png', '15.png', '150.png', '151.png', '152.png', '153.png', '154.png', '155.png', '156.png', '157.png', '158.png', '159.png', '16.png', '160.png', '161.png', '162.png', '163.png', '164.png', '165.png', '166.png', '167.png', '168.png', '169.png', '17.png', '170.png', '171.png', '172.png', '173.png', '174.png', '175.png', '176.png', '177.png', '178.png', '179.png', '18.png', '180.png', '181.png', '182.png', '183.png', '184.png', '185.png', '186.png', '187.png', '188.png', '189.png', '19.png', '190.png', '191.png', '192.png', '193.png', '194.png', '195.png', '196.png', '197.png', '198.png', '199.png', '2.png', '20.png', '200.png', '201.png', '202.png', '203.png', '204.png', '205.png', '206.png', '207.png', '208.png', '209.png', '21.png', '210.png', '211.png', '212.png', '213.png', '214.png', '215.png', '216.png', '217.png', '218.png', '219.png', '22.png', '220.png', '221.png', '222.png', '223.png', '224.png', '225.png', '226.png', '227.png', '228.png', '229.png', '23.png', '230.png', '231.png', '232.png', '233.png', '234.png', '235.png', '236.png', '237.png', '238.png', '239.png', '24.png', '240.png', '241.png', '242.png', '243.png', '244.png', '245.png', '246.png', '247.png', '248.png', '249.png', '25.png', '250.png', '251.png', '252.png', '253.png', '254.png', '255.png', '256.png', '257.png', '258.png', '259.png', '26.png', '260.png', '261.png', '262.png', '263.png', '264.png', '265.png', '266.png', '267.png', '268.png', '269.png', '27.png', '270.png', '271.png', '272.png', '273.png', '274.png', '275.png', '276.png', '277.png', '278.png', '279.png', '28.png', '280.png', '281.png', '282.png', '283.png', '284.png', '285.png', '286.png', '287.png', '288.png', '289.png', '29.png', '290.png', '291.png', '292.png', '293.png', '294.png', '295.png', '296.png', '297.png', '298.png', '299.png', '3.png', '30.png', '300.png', '301.png', '302.png', '303.png', '304.png', '305.png', '306.png', '307.png', '308.png', '309.png', '31.png', '310.png', '311.png', '312.png', '313.png', '314.png', '315.png', '316.png', '317.png', '318.png', '319.png', '32.png', '320.png', '321.png', '322.png', '323.png', '324.png', '325.png', '326.png', '327.png', '328.png', '329.png', '33.png', '330.png', '331.png', '332.png', '333.png', '334.png', '335.png', '336.png', '337.png', '338.png', '339.png', '34.png', '340.png', '341.png', '342.png', '343.png', '344.png', '345.png', '346.png', '347.png', '348.png', '349.png', '35.png', '350.png', '351.png', '352.png', '353.png', '354.png', '355.png', '356.png', '357.png', '358.png', '359.png', '36.png', '360.png', '361.png', '362.png', '363.png', '364.png', '365.png', '366.png', '367.png', '368.png', '369.png', '37.png', '370.png', '371.png', '372.png', '373.png', '374.png', '375.png', '376.png', '377.png', '378.png', '379.png', '38.png', '380.png', '381.png', '382.png', '383.png', '384.png', '385.png', '386.png', '387.png', '388.png', '389.png', '39.png', '390.png', '391.png', '392.png', '393.png', '394.png', '395.png', '396.png', '397.png', '398.png', '399.png', '4.png', '40.png', '400.png', '401.png', '402.png', '403.png', '404.png', '405.png', '406.png', '407.png', '408.png', '409.png', '41.png', '410.png', '411.png', '412.png', '413.png', '414.png', '415.png', '416.png', '417.png', '418.png', '419.png', '42.png', '420.png', '421.png', '422.png', '423.png', '424.png', '425.png', '426.png', '427.png', '428.png', '429.png', '43.png', '430.png', '431.png', '432.png', '433.png', '434.png', '435.png', '436.png', '437.png', '438.png', '439.png', '44.png', '440.png', '441.png', '442.png', '443.png', '444.png', '445.png', '446.png', '447.png', '448.png', '449.png', '45.png', '450.png', '451.png', '452.png', '453.png', '454.png', '455.png', '456.png', '457.png', '458.png', '459.png', '46.png', '460.png', '461.png', '462.png', '463.png', '464.png', '465.png', '466.png', '467.png', '468.png', '469.png', '47.png', '470.png', '471.png', '472.png', '473.png', '474.png', '475.png', '476.png', '477.png', '478.png', '479.png', '48.png', '480.png', '481.png', '482.png', '483.png', '484.png', '485.png', '486.png', '487.png', '488.png', '489.png', '49.png', '490.png', '491.png', '492.png', '493.png', '494.png', '495.png', '496.png', '497.png', '498.png', '499.png', '5.png', '50.png', '500.png', '501.png', '502.png', '503.png', '504.png', '505.png', '506.png', '507.png', '508.png', '509.png', '51.png', '510.png', '511.png', '512.png', '513.png', '514.png', '515.png', '516.png', '517.png', '518.png', '519.png', '52.png', '520.png', '521.png', '522.png', '523.png', '524.png', '525.png', '526.png', '527.png', '528.png', '529.png', '53.png', '530.png', '531.png', '532.png', '533.png', '534.png', '535.png', '536.png', '537.png', '538.png', '539.png', '54.png', '540.png', '541.png', '542.png', '543.png', '544.png', '545.png', '546.png', '547.png', '548.png', '549.png', '55.png', '550.png', '551.png', '552.png', '553.png', '554.png', '555.png', '556.png', '557.png', '558.png', '559.png', '56.png', '560.png', '561.png', '562.png', '563.png', '564.png', '565.png', '566.png', '567.png', '568.png', '569.png', '57.png', '570.png', '571.png', '572.png', '573.png', '574.png', '575.png', '576.png', '577.png', '578.png', '579.png', '58.png', '580.png', '581.png', '582.png', '583.png', '584.png', '585.png', '586.png', '587.png', '588.png', '589.png', '59.png', '590.png', '591.png', '592.png', '593.png', '594.png', '595.png', '596.png', '597.png', '598.png', '6.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '7.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '8.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '9.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png']\n"
          ]
        }
      ],
      "source": [
        "print(image_paths)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:47.541603893Z",
          "start_time": "2023-12-09T17:31:47.537787767Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkcKblBG-B7A",
        "outputId": "d70abf2a-3e98-4b1a-c6ad-96e54485d327"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 358\n",
            "Valid samples: 120\n",
            "Test samples: 120\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Разделение данных на обучающую, валидационную и тестовую выборки\n",
        "train_paths, test_paths = train_test_split(image_paths, test_size=0.2, random_state=42)\n",
        "train_paths, valid_paths = train_test_split(train_paths, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
        "\n",
        "# Проверка размеров выборок\n",
        "print(\"Train samples:\", len(train_paths))\n",
        "print(\"Valid samples:\", len(valid_paths))\n",
        "print(\"Test samples:\", len(test_paths))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:50.734029077Z",
          "start_time": "2023-12-09T17:31:50.711396595Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIazrOok-B7A",
        "outputId": "4600a60e-b592-42f6-85b5-1d49f6a0a248"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": [
        "train_images = [load_image(image_path) for image_path in train_paths]\n",
        "train_masks = [load_mask(mask_path) for mask_path in train_paths]\n",
        "train_images = np.array(train_images)\n",
        "train_masks = np.array(train_masks)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:51.949852051Z",
          "start_time": "2023-12-09T17:31:51.037635672Z"
        },
        "id": "N75Ubwyp-B7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": [
        "valid_images = [load_image(image_path) for image_path in valid_paths]\n",
        "valid_masks = [load_mask(mask_path) for mask_path in valid_paths]\n",
        "valid_images = np.array(valid_images)\n",
        "valid_masks = np.array(valid_masks)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:52.224873217Z",
          "start_time": "2023-12-09T17:31:51.951017122Z"
        },
        "id": "Nh_SxOO1-B7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "test_images = [load_image(image_path) for image_path in test_paths]\n",
        "test_masks = [load_mask(mask_path) for mask_path in test_paths]\n",
        "test_images = np.array(test_images)\n",
        "test_masks = np.array(test_masks)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:31:52.502350446Z",
          "start_time": "2023-12-09T17:31:52.265328792Z"
        },
        "id": "2eibI7uV-B7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [],
      "source": [
        "\n",
        "def unet_test_model(classes: int = 1):\n",
        "    tf.keras.backend.clear_session()\n",
        "    nb_filter = [32, 64, 128, 256, 512]\n",
        "    # Build U-Net++ model\n",
        "    inputs = Input((WIDTH, HEIGHT, 3))\n",
        "    s = Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "    c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.5)(c1)\n",
        "    c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    c1 = Dropout(0.5)(c1)\n",
        "    p1 = MaxPooling2D((2, 2), strides=(2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.5)(c2)\n",
        "    c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    c2 = Dropout(0.5)(c2)\n",
        "    p2 = MaxPooling2D((2, 2), strides=(2, 2))(c2)\n",
        "\n",
        "    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(c2)\n",
        "    conv1_2 = concatenate([up1_2, c1], name='merge12', axis=3)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_2)\n",
        "    c3 = Dropout(0.5)(c3)\n",
        "    c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    c3 = Dropout(0.5)(c3)\n",
        "\n",
        "    conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    conv3_1 = Dropout(0.5)(conv3_1)\n",
        "    conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3_1)\n",
        "    conv3_1 = Dropout(0.5)(conv3_1)\n",
        "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
        "\n",
        "    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
        "    conv2_2 = concatenate([up2_2, c2], name='merge22', axis=3)  #x10\n",
        "    conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_2)\n",
        "    conv2_2 = Dropout(0.5)(conv2_2)\n",
        "    conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_2)\n",
        "    conv2_2 = Dropout(0.5)(conv2_2)\n",
        "\n",
        "    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
        "    conv1_3 = concatenate([up1_3, c1, c3], name='merge13', axis=3)\n",
        "    conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_3)\n",
        "    conv1_3 = Dropout(0.5)(conv1_3)\n",
        "    conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_3)\n",
        "    conv1_3 = Dropout(0.5)(conv1_3)\n",
        "\n",
        "    conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool3)\n",
        "    conv4_1 = Dropout(0.5)(conv4_1)\n",
        "    conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4_1)\n",
        "    conv4_1 = Dropout(0.5)(conv4_1)\n",
        "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
        "\n",
        "    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
        "    conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3)  #x20\n",
        "    conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3_2)\n",
        "    conv3_2 = Dropout(0.5)(conv3_2)\n",
        "    conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3_2)\n",
        "    conv3_2 = Dropout(0.5)(conv3_2)\n",
        "\n",
        "    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
        "    conv2_3 = concatenate([up2_3, c2, conv2_2], name='merge23', axis=3)\n",
        "    conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_3)\n",
        "    conv2_3 = Dropout(0.5)(conv2_3)\n",
        "    conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_3)\n",
        "    conv2_3 = Dropout(0.5)(conv2_3)\n",
        "\n",
        "    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
        "    conv1_4 = concatenate([up1_4, c1, c3, conv1_3], name='merge14', axis=3)\n",
        "    conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_4)\n",
        "    conv1_4 = Dropout(0.5)(conv1_4)\n",
        "    conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_4)\n",
        "    conv1_4 = Dropout(0.5)(conv1_4)\n",
        "\n",
        "    conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool4)\n",
        "    conv5_1 = Dropout(0.5)(conv5_1)\n",
        "    conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv5_1)\n",
        "    conv5_1 = Dropout(0.5)(conv5_1)\n",
        "\n",
        "    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
        "    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3)  #x30\n",
        "    conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4_2)\n",
        "    conv4_2 = Dropout(0.5)(conv4_2)\n",
        "    conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4_2)\n",
        "    conv4_2 = Dropout(0.5)(conv4_2)\n",
        "\n",
        "    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
        "    conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n",
        "    conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3_3)\n",
        "    conv3_3 = Dropout(0.5)(conv3_3)\n",
        "    conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3_3)\n",
        "    conv3_3 = Dropout(0.5)(conv3_3)\n",
        "\n",
        "    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
        "    conv2_4 = concatenate([up2_4, c2, conv2_2, conv2_3], name='merge24', axis=3)\n",
        "    conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_4)\n",
        "    conv2_4 = Dropout(0.5)(conv2_4)\n",
        "    conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2_4)\n",
        "    conv2_4 = Dropout(0.5)(conv2_4)\n",
        "\n",
        "    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
        "    conv1_5 = concatenate([up1_5, c1, c3, conv1_3, conv1_4], name='merge15', axis=3)\n",
        "    conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_5)\n",
        "    conv1_5 = Dropout(0.5)(conv1_5)\n",
        "    conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1_5)\n",
        "    conv1_5 = Dropout(0.5)(conv1_5)\n",
        "\n",
        "    nestnet_output_4 = Conv2D(classes, (1, 1), activation='sigmoid', kernel_initializer='he_normal', name='output_4',\n",
        "                              padding='same')(conv1_5)\n",
        "    # output = Conv2D(\n",
        "    #     filters=classes,\n",
        "    #     kernel_size=(3, 3),\n",
        "    #     padding='same',\n",
        "    #     activation='softmax',\n",
        "    #     use_bias=True,\n",
        "    #     kernel_initializer='glorot_uniform',\n",
        "    #     name='final_conv',\n",
        "    # )(nestnet_output_4)\n",
        "\n",
        "    # create keras model instance\n",
        "    return Model(inputs=[inputs], outputs=\n",
        "    [nestnet_output_4])\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:37:46.485640854Z",
          "start_time": "2023-12-09T17:37:46.440392427Z"
        },
        "id": "ROQ4PVJj-B7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": [
        "LR = 0.0001\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:37:47.364145452Z",
          "start_time": "2023-12-09T17:37:47.352842529Z"
        },
        "id": "fyutaLiH-B7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def weighted_dice_coeff(y_true, y_pred, weight):\n",
        "    smooth = 1.\n",
        "    w, m1, m2 = weight * weight, y_true, y_pred\n",
        "    intersection = (m1 * m2)\n",
        "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
        "    return score\n",
        "\n",
        "\n",
        "def weighted_dice_loss(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    # if we want to get same size of output, kernel size must be odd number\n",
        "    if K.int_shape(y_pred)[1] == 128:\n",
        "        kernel_size = 11\n",
        "    elif K.int_shape(y_pred)[1] == 256:\n",
        "        kernel_size = 21\n",
        "    elif K.int_shape(y_pred)[1] == 512:\n",
        "        kernel_size = 21\n",
        "    elif K.int_shape(y_pred)[1] == 1024:\n",
        "        kernel_size = 41\n",
        "    else:\n",
        "        raise ValueError('Unexpected image size')\n",
        "    print(kernel_size)\n",
        "    averaged_mask = K.pool2d(\n",
        "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
        "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
        "    weight = K.ones_like(averaged_mask)\n",
        "    w0 = K.sum(weight)\n",
        "    weight += border * 2\n",
        "    w1 = K.sum(weight)\n",
        "    weight *= (w0 / w1)\n",
        "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def weighted_bce_loss(y_true, y_pred, weight):\n",
        "    # avoiding overflow\n",
        "    epsilon = 1e-7\n",
        "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
        "\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
        "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
        "           (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
        "    return K.sum(loss) / K.sum(weight)\n",
        "\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def weighted_bce_dice_loss(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # Остальной код функции...\n",
        "    if K.int_shape(y_pred)[1] == 128:\n",
        "        kernel_size = 11\n",
        "    elif K.int_shape(y_pred)[1] == 256:\n",
        "        kernel_size = 21\n",
        "    elif K.int_shape(y_pred)[1] == 512:\n",
        "        kernel_size = 21\n",
        "    elif K.int_shape(y_pred)[1] == 1024:\n",
        "        kernel_size = 41\n",
        "    else:\n",
        "        raise ValueError('Unexpected image size')\n",
        "    print(\"Size \", kernel_size)\n",
        "    averaged_mask = K.pool2d(\n",
        "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
        "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
        "    weight = K.ones_like(averaged_mask)\n",
        "    w0 = K.sum(weight)\n",
        "    weight += border * 2\n",
        "    w1 = K.sum(weight)\n",
        "    weight *= (w0 / w1)\n",
        "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
        "    return loss"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:37:49.520521902Z",
          "start_time": "2023-12-09T17:37:49.491608586Z"
        },
        "id": "OJ05eutz-B7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(result[0][0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "pQCIQ9BnFvxV",
        "outputId": "60c822ea-4a4f-48b2-9681-b30b72c9f4f2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5fcb53210983>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import IoU\n",
        "\n",
        "model = unet_test_model(CLASSES)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=bce_dice_loss,\n",
        "              metrics=[IoU(num_classes=CLASSES + 1, target_class_ids=\n",
        "              [i for i in range(CLASSES + 1)])])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:37:58.599558858Z",
          "start_time": "2023-12-09T17:37:57.757809607Z"
        },
        "id": "lfAvKpw9-B7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "Xjy4Pplm-B7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 83s 2s/step - loss: 4.2589 - io_u: 0.4486 - val_loss: 1.6029 - val_io_u: 0.4586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8dc0626350>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Создание и обучение модели U-Net\n",
        "model.fit(train_images, train_masks, validation_data=(valid_images, valid_masks), epochs=1, batch_size=16)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:38:00.973208048Z",
          "start_time": "2023-12-09T17:38:00.083543866Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwEMo-3P-B7F",
        "outputId": "96485aea-cfbe-4048-8cdc-664f6327cfe1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 27s 1s/step - loss: 2.1080 - io_u: 0.4554 - val_loss: 1.2533 - val_io_u: 0.4586\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 27s 1s/step - loss: 1.7742 - io_u: 0.4553 - val_loss: 1.2080 - val_io_u: 0.4586\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 27s 1s/step - loss: 1.5762 - io_u: 0.4553 - val_loss: 1.1971 - val_io_u: 0.4586\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 27s 1s/step - loss: 1.4538 - io_u: 0.4553 - val_loss: 1.1804 - val_io_u: 0.4586\n",
            "Epoch 5/5\n",
            " 3/23 [==>...........................] - ETA: 22s - loss: 1.4014 - io_u: 0.4567"
          ]
        }
      ],
      "source": [
        "# Создание и обучение модели U-Net\n",
        "model.fit(train_images, train_masks, validation_data=(valid_images, valid_masks), epochs=5, batch_size=16)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-05T11:57:46.312923332Z",
          "start_time": "2023-12-05T11:19:29.492824039Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xll1fPUU-B7F",
        "outputId": "53259c13-500b-4047-b145-230fc547a158"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Создание и обучение модели U-Net\n",
        "model.fit(train_images, train_masks, validation_data=(valid_images, valid_masks), epochs=20, batch_size=16)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-05T09:39:22.005824384Z",
          "start_time": "2023-12-05T09:10:41.692685728Z"
        },
        "id": "tkL9DDNW-B7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Создание и обучение модели U-Net\n",
        "model.fit(train_images, train_masks, validation_data=(valid_images, valid_masks), epochs=20, batch_size=16)"
      ],
      "metadata": {
        "id": "fm5PlXzT-B7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Создание и обучение модели U-Net\n",
        "model.fit(train_images, train_masks, validation_data=(valid_images, valid_masks), epochs=20, batch_size=16)"
      ],
      "metadata": {
        "id": "YVbay_VR-B7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, 'model')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-05T12:22:13.334078559Z",
          "start_time": "2023-12-05T12:22:07.128811572Z"
        },
        "id": "J3cGg8Je-B7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "result = model.predict(test_images)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:21:09.076499758Z",
          "start_time": "2023-12-09T17:20:40.641542787Z"
        },
        "id": "w29aoheE-B7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(result[0])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:21:53.495200530Z",
          "start_time": "2023-12-09T17:21:53.465913659Z"
        },
        "id": "zghLwt6l-B7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Предположим, что результат предсказания модели содержит вероятности пикселей для каждого класса\n",
        "# Размерность результатов предсказания: (batch_size, HEIGHT, WIDTH, num_classes)\n",
        "\n",
        "# Предположим, что результат предсказания модели содержит вероятности пикселей для каждого класса\n",
        "# Размерность результатов предсказания: (batch_size, HEIGHT, WIDTH, num_classes)\n",
        "num_classes = 7  # Количество классов (6 классов + 1 класс \"ничего\")\n",
        "threshold = 0.5  # Порог для принятия решения о наличии объекта на пикселе\n",
        "\n",
        "# Преобразование результатов предсказания в маски с максимальными значениями классов\n",
        "part = 100\n",
        "predicted_masks = result[:part]\n",
        "# true_masks = test_masks\n",
        "# Создание палитры цветов для каждого класса\n",
        "palette = [\n",
        "    (0, 0, 0),  # Класс \"ничего\" (черный цвет)\n",
        "    (255, 0, 0),  # Класс 1 (красный цвет)\n",
        "    (0, 255, 0),  # Класс 2 (зеленый цвет)\n",
        "    (0, 0, 255),  # Класс 3 (синий цвет)\n",
        "    (255, 255, 0),  # Класс 4 (желтый цвет)\n",
        "    (255, 0, 255),  # Класс 5 (пурпурный цвет)\n",
        "    (0, 255, 255),  # Класс 6 (бирюзовый цвет)\n",
        "    (255, 255, 255)\n",
        "]\n",
        "#\n",
        "# Создание изображений для каждого предсказанного класса\n",
        "for i in range(min(predicted_masks.shape[0], part)):\n",
        "    image = Image.new(\"RGB\",\n",
        "                      (\n",
        "                          WIDTH, HEIGHT\n",
        "                      )\n",
        "                      )\n",
        "    # true_mask = Image.new(\"RGB\",\n",
        "    #                   (\n",
        "    #                       WIDTH, HEIGHT\n",
        "    #                   )\n",
        "    #                   )\n",
        "    for y in range(\n",
        "            HEIGHT\n",
        "    ):\n",
        "        for x in range(\n",
        "                WIDTH\n",
        "        ):\n",
        "            if predicted_masks[i][y][x] >= threshold:\n",
        "                class_index = 7\n",
        "            else:\n",
        "                class_index = 0\n",
        "            # val = predicted_masks[i][x][y]\n",
        "            image.putpixel((x, y), palette[class_index])  #(int(val * 255), int(val * 255), int(val * 255)))\n",
        "            # if true_masks[i][y][x] >= threshold:\n",
        "            #     true_mask.putpixel((x, y), palette[7])\n",
        "            # else:\n",
        "            #     true_mask.putpixel((x, y), palette[0])\n",
        "    image.save(f\"result/predicted_image_{i}.png\")\n",
        "    # true_mask.save(f\"result_small_5/predicted_image_{i}_true.png\")\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-09T17:22:22.430266493Z",
          "start_time": "2023-12-09T17:22:00.891265460Z"
        },
        "id": "CFWDLO-2-B7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "yy4Gldre-B7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "gBVsmG4a-B7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(test_masks[0])"
      ],
      "metadata": {
        "id": "RR3PBXUM-B7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "AcNx8--i-B7I"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}